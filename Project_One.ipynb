{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "UyuXPnxBy51-",
    "outputId": "7ee31c56-e1ed-4cd9-bd95-c37dc1ecf0ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for tweepy\n",
      "Best match: tweepy 3.7.0\n",
      "Processing tweepy-3.7.0-py3.7.egg\n",
      "tweepy 3.7.0 is already the active version in easy-install.pth\n",
      "\n",
      "Using /Users/HayesMartens/anaconda3/lib/python3.7/site-packages/tweepy-3.7.0-py3.7.egg\n",
      "Processing dependencies for tweepy\n",
      "Finished processing dependencies for tweepy\n",
      "Requirement already satisfied: GoogleMaps in /Users/HayesMartens/anaconda3/lib/python3.7/site-packages (3.0.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.11.1 in /Users/HayesMartens/anaconda3/lib/python3.7/site-packages (from GoogleMaps) (2.19.1)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /Users/HayesMartens/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.11.1->GoogleMaps) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/HayesMartens/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.11.1->GoogleMaps) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/HayesMartens/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.11.1->GoogleMaps) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /Users/HayesMartens/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.11.1->GoogleMaps) (1.23)\n"
     ]
    }
   ],
   "source": [
    "!easy_install tweepy\n",
    "!pip install GoogleMaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import tweepy\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUbE7y-VzVa-"
   },
   "source": [
    "# Top Trending Diets of Twitter Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "rC27sP2oflbp",
    "outputId": "353f5ed4-7609-4e47-a201-80ee017549a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hugh g if true https://t.co/KspfIpKPBz\n",
      "Check out more of @SethMeyers‚Äô favorite #LNSM jokes of the week üëâ\n",
      "https://t.co/NLR8qaFFeX\n",
      "You guys coming tonight? I won‚Äôt wear the helmet. https://t.co/hnDOejukAj\n",
      "Supermodel Tyra Banks has announced she will be opening a beauty-focused theme park later this year called ‚ÄúModella‚Ä¶ https://t.co/v3PtqfjjBd\n",
      "https://t.co/49gJh4DNh7\n",
      "It's about time we got an indie Star Wars film!\n",
      "https://t.co/ltjkN4JViD https://t.co/NmOUysCmIP\n",
      "Stranded by Roxy Music. Iggy Pop. https://t.co/r6bRRxO68v\n",
      "Literally the opposite. https://t.co/vNwR8SF3eS\n",
      "RT @MattOswaltVA: I tried this with a girl but got lockjaw from having to go down on all her coworkers https://t.co/IdZQNjiZng\n",
      "Happy national pizza day, Teefurians! What's your favorite pizza topping? Hint: the correct answer is pretty much a‚Ä¶ https://t.co/eWK6fT0NpL\n",
      "Sundays are for: walk, talk, ride. \n",
      "\n",
      "#TWD returns tomorrow, followed by #TalkingDead and #RidewithNorman. https://t.co/lKAJEn8KsY\n",
      "Working out in Sactown! See me at the Punch Line today at 4:20!! Exclamation points!!! https://t.co/koiic3EBgy\n",
      "Thank you so much!!! So happy you made it out https://t.co/9P5xCsc3TZ\n",
      "‚Äútonight‚Äôs karaoke night, so i have to get there early enough to break the karaoke machine‚Äù\n",
      "\n",
      "- Nick Miller\n",
      "\n",
      "#peacefulprotest\n",
      "‚ÄúHundreds rally for right to endanger or kill their children and yours!‚Äù https://t.co/6mtoaKtQ5x\n",
      "RT @dsam4a: üö®The Medicare for All Act of 2019 will be introduced in the House any day nowüö®\n",
      "\n",
      "‚úîÔ∏èa single, public program\n",
      "‚úîÔ∏ètruly universal\n",
      "‚úîÔ∏è‚Ä¶\n",
      "Medicare for all is a struggle not just about health care, but about the heart and soul of our country ‚Äî about what‚Ä¶ https://t.co/6RG59rodAX\n",
      "It's got elements of all three, but is the most intense and complete thing I've ever done. https://t.co/K4Feb3FEFV\n",
      "@bluebear_21 I WOULD RUN THROUGH A MOTHERFUCKING WALL\n",
      "RT @ewarren: Let‚Äôs be clear: I won't take a dime of PAC money in this campaign. I won't take a single check from a federal lobbyist, or bil‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies and Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import tweepy\n",
    "\n",
    "api_key = \"NS0C667Vxg13Pd7WOSVB1w5Hz\"\n",
    "api_key_secret = \"vo3ewSknxwmgZSLtGJoIi10XPjoQDBVvii6gNsR3R7nf16ERpJ\"\n",
    "access_token = \"24253020-go2gWRKsgW0Zqe0VTBvyT3G2vCrh20taz9oGA5HrJ\"\n",
    "access_token_secret = \"UcnEnRboaYAFuLnExdoTAuMopLoBjItNMmLflYdxm1nTP\"\n",
    "\n",
    "\n",
    "# Tweepy\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "configure() got an unexpected keyword argument 'google_api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d8eea1d96ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AIzaSyBV5KGbc5xC3SwnAcaZFtmZL_FhRSlAqa4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: configure() got an unexpected keyword argument 'google_api_key'"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "from googlemaps import Client\n",
    "#!pip install gmaps\n",
    "\n",
    "google_api_key = \"AIzaSyBV5KGbc5xC3SwnAcaZFtmZL_FhRSlAqa4\"\n",
    "gmaps = Client(google_api_key)\n",
    "\n",
    "#fig = gmaps.figure()\n",
    "\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n",
    "gmaps.configure(google_api_key='AIzaSyBV5KGbc5xC3SwnAcaZFtmZL_FhRSlAqa4')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#address = \"Austin, Texas\"\n",
    "#def coor(address):\n",
    "    #results = gmaps.geocode(address)\n",
    "    #print(results)\n",
    "#coor(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url for Collecting 30-Day Endpoint API Data\n",
    "#https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\n",
    "\n",
    "# Initialize Variables\n",
    "paleo_location_list = []\n",
    "paleo_location_dict = {}\n",
    "count = 0\n",
    "\n",
    "# Get Data About Trending Diet Trends on Twitter: Paleo\n",
    "from requests_oauthlib import OAuth1\n",
    "\n",
    "url = \"https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\"\n",
    "auth = OAuth1(api_key, api_key_secret, access_token, access_token_secret)\n",
    "\n",
    "url_params = {'query': 'place_country:us #Paleo'}\n",
    "r = requests.get(url, auth=auth, params=url_params)\n",
    "\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in r.json()[\"results\"]:\n",
    "    #print(json.dumps(tweets, indent=4))\n",
    "    #print(tweets[\"user\"][\"location\"])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #Get and print location of tweet\n",
    "        user_name = tweet[\"user\"][\"screen_name\"]\n",
    "        location = tweet[\"user\"][\"location\"]\n",
    "        tweet_location = tweet[\"place\"][\"full_name\"]\n",
    "        lat, lng = geocoder.arcgis(tweet_location).latlng\n",
    "        print(f\"The user, {user_name}, is located in {tweet_location}, {lat}, {lng}\")\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        #Build dictionary\n",
    "        paleo_location_dict = {\n",
    "             \"user\": user_name,\n",
    "             \"tweet_location\": tweet_location,\n",
    "             \"lat\": lat,\n",
    "             \"lng\": lng\n",
    "            \n",
    "         }\n",
    "        \n",
    "        \n",
    "        # Add dictionary to list\n",
    "        paleo_location_list_update.append(paleo_locaton_dict)\n",
    "        \n",
    "        # Increment count\n",
    "        count = count + 1\n",
    "    except:\n",
    "         continue\n",
    "\n",
    "print(count)\n",
    "\n",
    "\n",
    "pale0_location_df = pd.DataFrame(W30_location_list_update)\n",
    "W30_location_df\n",
    "\n",
    "W30_location_df.to_csv('W30_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1734
    },
    "colab_type": "code",
    "id": "nmleBzjPzyie",
    "outputId": "5b768191-7907-407a-ca4c-f6ee3064edf9"
   },
   "outputs": [],
   "source": [
    "# Base url for Collecting 30-Day Endpoint API Data\n",
    "#https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\n",
    "\n",
    "\n",
    "# Initialize Variables\n",
    "paleo_location_list = []\n",
    "paleo_location_dict = {}\n",
    "count = 0\n",
    "\n",
    "# Get Data About Trending Diet Trends on Twitter: Paleo\n",
    "from requests_oauthlib import OAuth1\n",
    "\n",
    "url = \"https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json?query=paleo+diet\"\n",
    "auth = OAuth1(api_key, api_key_secret, access_token, access_token_secret)\n",
    "r = requests.get(url, auth = auth)\n",
    "#print(r.json())\n",
    "\n",
    "# Create Loop Search to assign variable names\n",
    "for tweets in r.json()[\"results\"]:\n",
    "    #print(json.dumps(tweets, indent=4))\n",
    "    #print(tweets[\"user\"][\"location\"])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #Get and print location of tweet\n",
    "        user_name = tweets[\"user\"][\"screen_name\"]\n",
    "        location = tweets[\"user\"][\"location\"]    \n",
    "        print(f\"The user, {user_name}, is located in {location}.\")\n",
    "\n",
    "\n",
    "        \n",
    "        #Build dictionary\n",
    "        paleo_location_dict = {\n",
    "             \"user\": user_name,\n",
    "             \"location\": location\n",
    "\n",
    "         }\n",
    "        \n",
    "        \n",
    "        # Add dictionary to list\n",
    "        paleo_location_list.append(paleo_location_dict)\n",
    "        \n",
    "        # Increment count\n",
    "        count = count + 1\n",
    "    except:\n",
    "         continue\n",
    "\n",
    "print(count)\n",
    "\n",
    "\n",
    "paleo_location_df = pd.DataFrame(paleo_location_list)\n",
    "paleo_location_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paleo_location_df.to_csv('Paleo_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder\n",
    "#pip install geocoder in terminal \n",
    "conda install -c anaconda basemap\n",
    "#install in terminal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "hecBqh9ZzzLe",
    "outputId": "69a971ee-0cb2-429c-fb2d-740ac886d840"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OAuth1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ed2484d05099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Get Data About Trending Diet Trends on Twitter: Paleo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOAuth1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key_secret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_token_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0murl_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'place_country:us #whole30'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OAuth1' is not defined"
     ]
    }
   ],
   "source": [
    "# Base url for Collecting 30-Day Endpoint API Data\n",
    "#https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\n",
    "\n",
    "\n",
    "# Initialize Variables\n",
    "W30_location_list = []\n",
    "W30_location_dict = {}\n",
    "count = 0\n",
    "\n",
    "# Get Data About Trending Diet Trends on Twitter: Paleo\n",
    "url = \"https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\"\n",
    "auth = OAuth1(api_key, api_key_secret, access_token, access_token_secret)\n",
    "\n",
    "url_params = {'query': 'place_country:us #whole30'}\n",
    "r = requests.get(url, auth=auth, params=url_params)\n",
    "\n",
    "print(r.json())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-beeaf55d694b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(json.dumps(tweets, indent=4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(tweets[\"user\"][\"location\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Loop Search to assign variable names\n",
    "\n",
    "W30_location_list_update = []\n",
    "\n",
    "\n",
    "\n",
    "for tweet in r.json()[\"results\"]:\n",
    "    #print(json.dumps(tweets, indent=4))\n",
    "    #print(tweets[\"user\"][\"location\"])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #Get and print location of tweet\n",
    "        user_name = tweet[\"user\"][\"screen_name\"]\n",
    "        location = tweet[\"user\"][\"location\"]\n",
    "        tweet_location = tweet[\"place\"][\"full_name\"]\n",
    "        lat, lng = geocoder.arcgis(tweet_location).latlng\n",
    "        print(f\"The user, {user_name}, is located in {tweet_location}, {lat}, {lng}\")\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        #Build dictionary\n",
    "        W30_location_dictionary = {\n",
    "             \"user\": user_name,\n",
    "             \"tweet_location\": tweet_location,\n",
    "             \"lat\": lat,\n",
    "             \"lng\": lng\n",
    "            \n",
    "         }\n",
    "        \n",
    "        \n",
    "        # Add dictionary to list\n",
    "        W30_location_list_update.append(W30_location_dictionary)\n",
    "        \n",
    "        # Increment count\n",
    "        count = count + 1\n",
    "    except:\n",
    "         continue\n",
    "\n",
    "print(count)\n",
    "\n",
    "\n",
    "W30_location_df = pd.DataFrame(W30_location_list_update)\n",
    "\n",
    "W30_location_df\n",
    "\n",
    "#W30_location_df.to_csv('W30_Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.78551</td>\n",
       "      <td>-78.64267</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>FoxLiquorBar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.06908</td>\n",
       "      <td>-79.79503</td>\n",
       "      <td>Greensboro, NC</td>\n",
       "      <td>Rodney_Crouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.76672</td>\n",
       "      <td>-118.19240</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>TastyYummies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.47203</td>\n",
       "      <td>-97.52107</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>OKCHomeSales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.69245</td>\n",
       "      <td>-73.99036</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>katycopes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat        lng     tweet_location           user\n",
       "0  35.78551  -78.64267        Raleigh, NC   FoxLiquorBar\n",
       "1  36.06908  -79.79503     Greensboro, NC  Rodney_Crouse\n",
       "2  33.76672 -118.19240     Long Beach, CA   TastyYummies\n",
       "3  35.47203  -97.52107  Oklahoma City, OK   OKCHomeSales\n",
       "4  40.69245  -73.99036       Brooklyn, NY      katycopes"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import tweepy\n",
    "\n",
    "file = \"W30_Data2.csv\"\n",
    "W30Data_df = pd.read_csv(file)\n",
    "W30Data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.78551</td>\n",
       "      <td>-78.64267</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>FoxLiquorBar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.06908</td>\n",
       "      <td>-79.79503</td>\n",
       "      <td>Greensboro, NC</td>\n",
       "      <td>Rodney_Crouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.76672</td>\n",
       "      <td>-118.19240</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>TastyYummies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.47203</td>\n",
       "      <td>-97.52107</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>OKCHomeSales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.69245</td>\n",
       "      <td>-73.99036</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>katycopes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat        lng     tweet_location           user\n",
       "0  35.78551  -78.64267        Raleigh, NC   FoxLiquorBar\n",
       "1  36.06908  -79.79503     Greensboro, NC  Rodney_Crouse\n",
       "2  33.76672 -118.19240     Long Beach, CA   TastyYummies\n",
       "3  35.47203  -97.52107  Oklahoma City, OK   OKCHomeSales\n",
       "4  40.69245  -73.99036       Brooklyn, NY      katycopes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop any NaN's \n",
    "W30_data_split_no_missing = W30Data_df.dropna()\n",
    "W30_data_split_no_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.78551</td>\n",
       "      <td>-78.64267</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>FoxLiquorBar</td>\n",
       "      <td>NC</td>\n",
       "      <td>Raleigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.06908</td>\n",
       "      <td>-79.79503</td>\n",
       "      <td>Greensboro, NC</td>\n",
       "      <td>Rodney_Crouse</td>\n",
       "      <td>NC</td>\n",
       "      <td>Greensboro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.76672</td>\n",
       "      <td>-118.19240</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>TastyYummies</td>\n",
       "      <td>CA</td>\n",
       "      <td>Long Beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.47203</td>\n",
       "      <td>-97.52107</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>OKCHomeSales</td>\n",
       "      <td>OK</td>\n",
       "      <td>Oklahoma City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.69245</td>\n",
       "      <td>-73.99036</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>katycopes</td>\n",
       "      <td>NY</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat        lng     tweet_location           user state           city\n",
       "0  35.78551  -78.64267        Raleigh, NC   FoxLiquorBar    NC        Raleigh\n",
       "1  36.06908  -79.79503     Greensboro, NC  Rodney_Crouse    NC     Greensboro\n",
       "2  33.76672 -118.19240     Long Beach, CA   TastyYummies    CA     Long Beach\n",
       "3  35.47203  -97.52107  Oklahoma City, OK   OKCHomeSales    OK  Oklahoma City\n",
       "4  40.69245  -73.99036       Brooklyn, NY      katycopes    NY       Brooklyn"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create open columns\n",
    "\n",
    "W30_data_split_no_missing[\"state\"] = \"\"\n",
    "W30_data_split_no_missing[\"city\"] = \"\"\n",
    "\n",
    "#split city and state\n",
    "W30_data_split_no_missing[[\"city\", \"state\"]]= W30_data_split_no_missing[\"tweet_location\"].str.split(\",\", expand=True)\n",
    "W30_data_split_no_missing.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>33.42551</td>\n",
       "      <td>-111.937240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>34.97711</td>\n",
       "      <td>-118.994403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>39.81589</td>\n",
       "      <td>-105.076325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>41.56266</td>\n",
       "      <td>-72.649840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>27.94653</td>\n",
       "      <td>-82.459270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat         lng\n",
       "state                      \n",
       " AZ    33.42551 -111.937240\n",
       " CA    34.97711 -118.994403\n",
       " CO    39.81589 -105.076325\n",
       " CT    41.56266  -72.649840\n",
       " FL    27.94653  -82.459270"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby \"state\" and get the mean (average) location from each state\n",
    "locations = W30_data_split_no_missing.groupby(\"state\").mean()\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " AZ     1\n",
       " CA    10\n",
       " CO     2\n",
       " CT     1\n",
       " FL     1\n",
       " GA     1\n",
       " IA     4\n",
       " IL     5\n",
       " IN     1\n",
       " KS     1\n",
       " KY     1\n",
       " MO    10\n",
       " NC     5\n",
       " NJ     5\n",
       " NY     8\n",
       " OH     3\n",
       " OK     1\n",
       " OR     2\n",
       " RI     1\n",
       " SC     1\n",
       " TN     1\n",
       " TX     5\n",
       " UT     1\n",
       " VA     3\n",
       " WA     7\n",
       " WV     1\n",
       " WY     2\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value Count each \"state\" (total tweets per state) and sort index by alphabetical order so it aligns with locations\n",
    "location_counts = W30_data_split_no_missing[\"state\"].value_counts()\n",
    "reorganized_location_count = location_counts.sort_index()\n",
    "reorganized_location_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da54afeb64ba4261996cdc2acf591eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Heatmap\n",
    "fig = gmaps.figure()\n",
    "# Create heat layer\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights=reorganized_location_count, dissipating=False, max_intensity=10, point_radius=1)\n",
    "# Add Layer \n",
    "fig.add_layer(heat_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a88d391518ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# load the shapefile, use the name 'states'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadshapefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'st99_d00'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'states'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrawbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import math\n",
    "\n",
    "scale = 5\n",
    "\n",
    "map = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "        projection='lcc',lat_1=32,lat_2=45,lon_0=-95)\n",
    "\n",
    "# load the shapefile, use the name 'states'\n",
    "m.readshapefile('st99_d00', name='states', drawbounds=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot locate st99_d00.shp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4f792dee6892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m## http://www.census.gov/geo/www/cob/st2000.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m shp_info = m.readshapefile('st99_d00','states',drawbounds=True,\n\u001b[0;32m---> 37\u001b[0;31m                            linewidth=0.45,color='gray')\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mshp_info_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadshapefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'st99_d00'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'states'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrawbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mpl_toolkits/basemap/__init__.py\u001b[0m in \u001b[0;36mreadshapefile\u001b[0;34m(self, shapefile, name, drawbounds, zorder, linewidth, color, antialiased, ax, default_encoding)\u001b[0m\n\u001b[1;32m   2132\u001b[0m         \u001b[0mshp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s.shp'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mshapefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot locate %s.shp'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mshapefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s.shx'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mshapefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot locate %s.shx'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mshapefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot locate st99_d00.shp"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# libraries\n",
    "#import basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import tweepy\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    " \n",
    "# Make a data frame with the GPS of a few cities:\n",
    "#data = pd.DataFrame({\n",
    "#'lat':[-58, 2, 145, 30.32, -4.03, -73.57, 36.82, -38.5],\n",
    "#'lon':[-34, 49, -38, 59.93, 5.33, 45.52, -1.29, -12.97],\n",
    "#'name':['Buenos Aires', 'Paris', 'melbourne', 'St Petersbourg', 'Abidjan', 'Montreal', 'Nairobi', 'Salvador']\n",
    "#})\n",
    " \n",
    "from matplotlib.colors import rgb2hex, Normalize\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Lambert Conformal map of lower 48 states.\n",
    "m = Basemap(llcrnrlon=-119,llcrnrlat=20,urcrnrlon=-64,urcrnrlat=49,\n",
    "            projection='lcc',lat_1=33,lat_2=45,lon_0=-95)\n",
    "\n",
    "# Mercator projection, for Alaska and Hawaii\n",
    "m_ = Basemap(llcrnrlon=-190,llcrnrlat=20,urcrnrlon=-143,urcrnrlat=46,\n",
    "            projection='merc',lat_ts=20)  # do not change these numbers\n",
    "\n",
    "#%% ---------   draw state boundaries  ----------------------------------------\n",
    "## data from U.S Census Bureau\n",
    "## http://www.census.gov/geo/www/cob/st2000.html\n",
    "shp_info = m.readshapefile('st99_d00','states',drawbounds=True,\n",
    "                           linewidth=0.45,color='gray')\n",
    "shp_info_ = m_.readshapefile('st99_d00','states',drawbounds=False)\n",
    "\n",
    "\n",
    " \n",
    "# Add a marker per city of the data frame!\n",
    "#m.plot(data['lat'], data['lon'], linestyle='none', marker=\"o\", markersize=16, alpha=0.6, c=\"orange\", markeredgecolor=\"black\", markeredgewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"W30_Data2.csv\"\n",
    "file_df = pd.read_csv(file)\n",
    "\n",
    "UniqueCities = pd.DataFrame(index=[0], columns=['Unique Cities'])\n",
    "\n",
    "UniqueCities['Unique Cities'][0] = len(file_df[\"tweet_location\"].unique())\n",
    "\n",
    "UniqueCities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "clgIIbxcJPER",
    "outputId": "1fc868a0-f26a-4e34-fba5-6f5a1c7fd656"
   },
   "outputs": [],
   "source": [
    "# Base url for Collecting 30-Day Endpoint API Data\n",
    "#https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\n",
    "\n",
    "\n",
    "# Initialize Variables\n",
    "keto_location_list = []\n",
    "keto_location_dict = {}\n",
    "count = 0\n",
    "\n",
    "# Get Data About Trending Diet Trends on Twitter: Paleo\n",
    "from requests_oauthlib import OAuth1\n",
    "\n",
    "url = \"https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json?query=keto+diet\"\n",
    "auth = OAuth1(api_key, api_key_secret, access_token, access_token_secret)\n",
    "r = requests.get(url, auth = auth)\n",
    "#print(r.json())\n",
    "\n",
    "\n",
    "# Create Loop Search to assign variable names\n",
    "for tweets in r.json()[\"results\"]:\n",
    "    #print(json.dumps(tweets, indent=4))\n",
    "    #print(tweets[\"user\"][\"location\"])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #Get and print location of tweet\n",
    "        user_name = tweets[\"user\"][\"screen_name\"]\n",
    "        location = tweets[\"user\"][\"location\"]    \n",
    "        print(f\"The user, {user_name}, is located in {location}.\")\n",
    "\n",
    "\n",
    "        \n",
    "        #Build dictionary\n",
    "        keto_location_dict = {\n",
    "             \"user\": user_name,\n",
    "             \"location\": location\n",
    "\n",
    "         }\n",
    "        \n",
    "        \n",
    "        # Add dictionary to list\n",
    "        keto_location_list.append(keto_location_dict)\n",
    "        \n",
    "        # Increment count\n",
    "        count = count + 1\n",
    "    except:\n",
    "         continue\n",
    "\n",
    "print(count)\n",
    "\n",
    "\n",
    "keto_location_df = pd.DataFrame(keto_location_list)\n",
    "keto_location_df\n",
    "\n",
    "keto_location_df.to_csv('keto_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "t_SDeV9oJT9n",
    "outputId": "63349b26-1ce4-4ebd-c35a-b5c63f1021ca"
   },
   "outputs": [],
   "source": [
    "# Base url for Collecting 30-Day Endpoint API Data\n",
    "#https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json\n",
    "\n",
    "\n",
    "# Initialize Variables\n",
    "weight_watchers_location_list = []\n",
    "weight_watchers_location_dict = {}\n",
    "count = 0\n",
    "\n",
    "# Get Data About Trending Diet Trends on Twitter: Paleo\n",
    "from requests_oauthlib import OAuth1\n",
    "\n",
    "url = \"https://api.twitter.com/1.1/tweets/search/30day/DataAnalyticsProject.json?query=weightwatchers+diet\"\n",
    "auth = OAuth1(api_key, api_key_secret, access_token, access_token_secret)\n",
    "r = requests.get(url, auth = auth)\n",
    "#print(r.json())\n",
    "\n",
    "\n",
    "# Create Loop Search to assign variable names\n",
    "for tweets in r.json()[\"results\"]:\n",
    "    #print(json.dumps(tweets, indent=4))\n",
    "    #print(tweets[\"user\"][\"location\"])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #Get and print location of tweet\n",
    "        user_name = tweets[\"user\"][\"screen_name\"]\n",
    "        location = tweets[\"user\"][\"location\"]    \n",
    "        print(f\"The user, {user_name}, is located in {location}.\")\n",
    "\n",
    "\n",
    "        \n",
    "        #Build dictionary\n",
    "        W30_location_dict = {\n",
    "             \"user\": user_name,\n",
    "             \"location\": location\n",
    "\n",
    "         }\n",
    "        \n",
    "        \n",
    "        # Add dictionary to list\n",
    "        weight_watchers_location_list.append(weight_watchers_location_dict)\n",
    "        \n",
    "        # Increment count\n",
    "        count = count + 1\n",
    "    except:\n",
    "         continue\n",
    "\n",
    "print(count)\n",
    "\n",
    "\n",
    "weight_watchers_location_df = pd.DataFrame(weight_watchers_location_list)\n",
    "weight_watchers_location_df\n",
    "\n",
    "weight_watchers_location_df.to_csv('weight_watchers_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_ZIS83GqZQH"
   },
   "outputs": [],
   "source": [
    "# Prepare visualization data\n",
    "\n",
    "\n",
    "# Build heatmap\n",
    "\n",
    "\n",
    "# Export & Save Data Into a .csv.\n",
    "# diet_data.to_csv(\"./data/diet_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project One.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
